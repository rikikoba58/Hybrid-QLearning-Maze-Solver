# Hybrid-QLearning-Maze-Solver
Q-Learning x GA: Hybrid Pathfinding Simulator
1. 概要
本プロジェクトは、強化学習（Q-Learning）と遺伝的アルゴリズム（GA）を組み合わせたハイブリッド手法により、未知の迷路環境において最短かつ安全な経路を自律探索するシミュレーターです。

2. 技術的特徴・実装の工夫
■ Q-Learning × GA ハイブリッド
局所最適解の打破: Q学習が一度見つけたルートに固執する性質に対し、GAの突然変異（Mutation）を導入。これにより、常に「別ルート」の可能性を探索し続け、より多様な最適解を発見します。

適応的探索: 世代（Generation）が進むにつれて突然変異率を動的に下げることで、後半は学習の収束性を高める設計にしています。

■ 意思決定ロジック：待機（Stay）戦略
動的リスク回避: 「上下左右」に加え「待機（Stay）」のアクションを実装。障害物が接近している際に「やり過ごす」という高度な判断を学習可能にしました。

報酬設計の最適化: 衝突リスクに応じた負の報酬と、安全な待機に対する報酬バランスを調整し、安全性と効率性の両立を実現しています。

■ Explainable AI (判断根拠の可視化)
Q値ヒートマップ: 各セルの最大Q値を背景色の濃淡で表示。AIがどの経路を「価値が高い」と判断しているかをリアルタイムで可視化します。

定量的メトリクス: ステップ数、平均成功ステップ数に加え、**衝突率（Conflict Rate）**を算出。アルゴリズムの性能を客観的な数値で評価できます。

3. 基本仕様
操作方法:

[R]: 迷路をランダム再生成し、学習をリセット

[Space]: 実行速度の切り替え（通常/高速）

カラー定義:

青色: エージェント（学習主体）

赤色: 動的障害物（衝突判定あり）

緑色: ゴール

黒色: 壁

4. 動作環境
Python 3.10+

Pygame / NumPy
